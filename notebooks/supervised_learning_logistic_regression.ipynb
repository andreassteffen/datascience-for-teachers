{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../data/images/dl_logos.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum\n",
    "* keras library\n",
    "* data loading and preprocessing \n",
    "* build simple logistic regression model\n",
    "* add updateable plot \n",
    "* build first neural network\n",
    "* play with the cool stuff: activations, drop-out, stochastic gradient descent\n",
    "* visualize the receptive fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# import modules and set plot environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import keras\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check keras version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMNIST(X,Y,  maxN=30, print_digits=True):\n",
    "    # plot pixels\n",
    "    plt.gray()\n",
    "    fig = plt.figure( figsize=(16,7) )\n",
    "    for i in range(0,maxN):\n",
    "        if print_digits:\n",
    "            ax = fig.add_subplot(3,10,i+1, title='Digit: ' + str(Y[i,:].argmax()) )\n",
    "        else:\n",
    "            ax = fig.add_subplot(3,10,i+1)\n",
    "        \n",
    "        ax.matshow(X[i,:].reshape((28,28)).astype(float))\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMNIST(X_train, Y_train, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# plain logistic regression, to keep it simple and fast\n",
    "<img src=\"../data/images/logreg.png\" width=\"800\">\n",
    "<img src=\"../data/images/sigmoid.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation\n",
    "\n",
    "logreg = Sequential()\n",
    "\n",
    "logreg.add(Flatten(input_shape=(28, 28, 1)))\n",
    "logreg.add(Dense(10))\n",
    "logreg.add(Activation('softmax'))\n",
    "\n",
    "logreg.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make updatable plot to show training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        #self.fig = plt.subplots(figsize=(16, 8), ncols=2)\n",
    "        #self.fig = plt.figure()\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.i += 1\n",
    "        plt.subplots(figsize=(16, 8), ncols=2)\n",
    "        clear_output(wait=True)\n",
    "        plt.subplot(221)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.subplot(222)\n",
    "        plt.plot(self.x, self.acc, label=\"accuracy\")\n",
    "        plt.plot(self.x, self.val_acc, label=\"val_accuracy\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "ShowLoss = PlotLossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Sequential()\n",
    "\n",
    "logreg.add(Flatten(input_shape=(28, 28, 1)))\n",
    "logreg.add(Dense(10))\n",
    "logreg.add(Activation('softmax'))\n",
    "logreg.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "logreg.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[ShowLoss],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot receptive fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMNIST(logreg.get_weights()[0].T, Y_train, 10,print_digits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = logreg.predict(X_test[0:50,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMNIST(X_test, label, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple two layer neural network\n",
    "<img src=\"../data/images/nnet2.png\" width=\"800\">\n",
    "<img src=\"../data/images/sigmoid.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNet = Sequential()\n",
    "\n",
    "NNet.add(Flatten(input_shape=(28, 28, 1)))\n",
    "NNet.add(Dense(50,  activation='sigmoid'))\n",
    "NNet.add(Dense(10))\n",
    "NNet.add(Activation('softmax'))\n",
    "NNet.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "NNet.fit(X_train, Y_train,\n",
    "          epochs=25,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[ShowLoss],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# changing the activation functions\n",
    "\n",
    "<img src=\"../data/images/activation.PNG\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNet = Sequential()\n",
    "\n",
    "NNet.add(Flatten(input_shape=(28, 28, 1)))\n",
    "NNet.add(Dense(50,  activation='relu'))\n",
    "NNet.add(Dense(10))\n",
    "NNet.add(Activation('softmax'))\n",
    "NNet.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "NNet.fit(X_train, Y_train,\n",
    "          epochs=25,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[ShowLoss],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model regulariation with dropout\n",
    "<img src=\"../data/images/dropout.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNet = Sequential()\n",
    "\n",
    "NNet.add(Flatten(input_shape=(28, 28, 1)))\n",
    "NNet.add(Dense(50,  activation='relu'))\n",
    "NNet.add(Dropout(0.25))\n",
    "NNet.add(Dense(10))\n",
    "NNet.add(Activation('softmax'))\n",
    "NNet.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "NNet.fit(X_train, Y_train,\n",
    "          epochs=25,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[ShowLoss],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model regulariation by stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNet = Sequential()\n",
    "NNet.add(Flatten(input_shape=(28, 28, 1)))\n",
    "NNet.add(Dense(50,  activation='relu'))\n",
    "NNet.add(Dropout(0.25))\n",
    "NNet.add(Dense(10))\n",
    "NNet.add(Activation('softmax'))\n",
    "NNet.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "NNet.fit(X_train, Y_train,\n",
    "          epochs=25,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[ShowLoss],\n",
    "          verbose=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unsupervised learning - autoencoders\n",
    "<img src=\"../data/images/autoencoder.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "x_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "x_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "\n",
    "\n",
    "encoding_dim = 32 \n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dropout(0.5)(input_img)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "class PlotAELossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        plt.subplots(figsize=(8, 4), ncols=1)\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "  \n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "ShowAELoss = PlotAELossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                callbacks=[ShowAELoss],\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build encoder and decoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enode and reconstruct some test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMNIST(x_test, label, 10,print_digits=False)\n",
    "plotMNIST(decoded_imgs, label, 10,print_digits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
